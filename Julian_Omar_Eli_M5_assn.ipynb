{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Classification Metrics Module 5 Assignment.\n",
    "\n",
    "## Group members:\n",
    "    \n",
    "    - Eli Weiss.\n",
    "    - Julian Ruggiero.\n",
    "    - Omar M. Hussein.\n",
    "    \n",
    "## Introduction\n",
    "\n",
    "In this assignment we are going to be creating several functions to measure the classification metrics of our binary classification model including accuracy, precision, recall (sensitivity), specificity and f1 score. Additionally, we will calculate the ROC and AUC and compare it to the ones populated by sklearn prebuilt functions.\n",
    "\n",
    "The data set was provided along with the assignment instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1)__ Load the provided M5_Data.csv file to your DAV 6150 Github Repository.\n",
    "\n",
    "Here we are only going to load the 3 columns that we need for the assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2)__ Then, using a Jupyter Notebook, read the data set from your Github repository and load it into a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(181, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>scored.class</th>\n",
       "      <th>scored.probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.328452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.273190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.109660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.055998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.100491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  scored.class  scored.probability\n",
       "0      0             0            0.328452\n",
       "1      0             0            0.273190\n",
       "2      1             0            0.109660\n",
       "3      0             0            0.055998\n",
       "4      0             0            0.100491"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#I read and save the dataset from my GitHub page using pd.read_csv\n",
    "df=pd.read_csv('https://raw.githubusercontent.com/enwweiss/DAV-6150/master/M5_Data.csv')\n",
    "\n",
    "#I print the shape to verify that is the same as the one documented (9568,5)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "whenever the scored.probability is:\n",
    "- lower than '0.5', the model predicted a 0 for scored.class column.\n",
    "- greater than '0.5', the model predicted a 1 for scored.class column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 181 entries, 0 to 180\n",
      "Data columns (total 3 columns):\n",
      "class                 181 non-null int64\n",
      "scored.class          181 non-null int64\n",
      "scored.probability    181 non-null float64\n",
      "dtypes: float64(1), int64(2)\n",
      "memory usage: 4.3 KB\n"
     ]
    }
   ],
   "source": [
    "#checking data types and if there are any null values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __class:__ the actual classification for the observation<br/>\n",
    "- __scored.class:__ the predicted classification for the observation (can only be ‘0’ or ‘1’; identified by\n",
    "comparing the classification model’s probability score (i.e., the likelihood that the correct classification\n",
    "for an observation is a ‘1’) for the observation against a 0.50 threshold))<br/>\n",
    "- __scored.probability:__ the classification model’s probability score (i.e., the likelihood that the correct\n",
    "classification for an observation is a ‘1’) for the observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3)__ Use Pandas’ __crosstab()__ function to calculate the contents of a confusion matrix for the data. Make sure you closely examine the output e.g., do the rows represent the actual or the predicted classification? What about the columns? (HINT: A good way to ensure you understand the output of the __crosstab()__ function is to check the __value_counts()__ for the dataframe columns you’ve used as input to the __crosstab()__ function. When observing the __value_counts()__, determine whether the rows or columns in the crosstab() output sum to the respective __value_counts()__ figures)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So here we count the total number of True positives, False positives, False negatives and True negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we display the False Negative and the True Negative counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    119\n",
       "1      5\n",
       "Name: scored.class, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking value counts \n",
    "df[df['class'] == 0]['scored.class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we display the True postive and the False postive counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    30\n",
       "1    27\n",
       "Name: scored.class, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking value counts\n",
    "df[df['class'] == 1]['scored.class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__4)__ Extract the individual confusion matrix values (i.e., True Positive, False Positive, True Negative, False Negative) from the output of the __crosstab()__ function and save them for later use (e.g., save them each to individual variables or to the data structure of your choice). Knowing how to properly extract these values from the output of crosstab() will serve you well throughout the remainder of the assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the pd.crosstab and provide the actual class and scored.class to get the complete confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scored.class    0   1\n",
      "class                \n",
      "0             119   5\n",
      "1              30  27\n"
     ]
    }
   ],
   "source": [
    "CF = pd.crosstab(df['class'],df['scored.class'])\n",
    "print(CF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the values provided by the crosstab function matches the value_counts() in the original from previous task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__5)__ Write a Python function that accepts as input the actual and predicted classifications for any binary classification data and then calculates and returns the __accuracy__ metric for the predictions without utilizing any pre-built Python accuracy metric calculation functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First define a helper function to be used with several tasks that follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_confusion_elements(actual_class, predicted_class):\n",
    "    \"\"\"Helper function that creates a confusion matrix and return its 4 elements for a\n",
    "    binary classification\"\"\"\n",
    "    conf_matrix = pd.crosstab(actual_class, predicted_class)\n",
    "\n",
    "    \n",
    "    tp = conf_matrix[1][1]\n",
    "    tn = conf_matrix[0][0]\n",
    "    fp = conf_matrix[1][0]\n",
    "    fn = conf_matrix[0][1]\n",
    "    \n",
    "    #returns the 4 elements\n",
    "    return tp,tn,fp,fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a function to get the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_classification_accuracy(actual_class, predicted_class):\n",
    "    \"\"\"Receives 2 list/series with the actual and predicted classifications \n",
    "    for any binary classification data and returns the accuracy metric\"\"\"\n",
    "    \n",
    "    tp,tn,fp,fn = get_confusion_elements(actual_class, predicted_class)\n",
    "    \n",
    "    accuracy = (tp+tn)/(tp+fp+fn+tn)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.806629834254\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "accuracy = get_classification_accuracy(df['class'],df['scored.class'])\n",
    "print(\"Accuracy: \",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can se that we have an accuracy of 0.8066"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__6)__ Write a Python function that accepts as input the actual and predicted classifications for any binary classification data and then calculates and returns the __precision__ metric for the predictions without utilizing any pre-built Python classification metric calculation functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a function to get the precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classification_precision(actual_class, predicted_class):\n",
    "    \"\"\"Receives 2 list/series with the actual and predicted classifications \n",
    "    for any binary classification data and returns the precision metric\"\"\"\n",
    "    \n",
    "    tp,tn,fp,fn = get_confusion_elements(actual_class, predicted_class)\n",
    "    \n",
    "    precision = tp / (tp+fp)\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.84375\n"
     ]
    }
   ],
   "source": [
    "precision = classification_precision(df['class'],df['scored.class'])\n",
    "print(\"Precision: \",precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We achieved a precision of 0.84375"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__7)__ Write a Python function that accepts as input the actual and predicted classifications for any binary classification data and then calculates and returns the __sensitivity__ metric for the predictions without utilizing any pre-built Python classification metric calculation functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a function to get the sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classification_sensitivity(actual_class, predicted_class):\n",
    "    \"\"\"\n",
    "    Receives 2 list/series with the actual and predicted classifications \n",
    "    for any binary classification data and returns the sensitivity metric\n",
    "    \"\"\"\n",
    "    \n",
    "    tp,tn,fp,fn = get_confusion_elements(actual_class, predicted_class)\n",
    "    \n",
    "    sensitivity = tp/(tp+fn)\n",
    "    return sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity:  0.473684210526\n"
     ]
    }
   ],
   "source": [
    "sensitivity = classification_sensitivity(df['class'],df['scored.class'])\n",
    "print(\"Sensitivity: \",sensitivity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We achieved a sensitivity of 0.4736"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__8)__ Write a Python function that accepts as input the actual and predicted classifications for any binary classification data and then calculates and returns the __specificity__ metric for the predictions without utilizing any pre-built Python classification metric calculation functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a function to get the specificity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classification_specificity(actual_class, predicted_class):\n",
    "    \"\"\"\n",
    "    Receives 2 list/series with the actual and predicted classifications \n",
    "    for any binary classification data and returns the specificity metric\n",
    "    \"\"\"\n",
    "    \n",
    "    tp,tn,fp,fn = get_confusion_elements(actual_class, predicted_class)\n",
    "    \n",
    "    specificity = tn/(tn+fn)\n",
    "    return specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity:  0.798657718121\n"
     ]
    }
   ],
   "source": [
    "specificity = classification_specificity(df['class'],df['scored.class'])\n",
    "print(\"Specificity: \",specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We achieved a specificity of 0.7986"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__9)__ Write a Python function that accepts as input the actual and predicted classifications for any binary classification data and then calculates and returns the __F1 Score__ metric for the predictions without utilizing any pre-built Python classification metric calculation functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a function to get the F1 Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classification_f1_score(actual_class, predicted_class):\n",
    "    \"\"\"\n",
    "    Receives 2 list/series with the actual and predicted classifications \n",
    "    for any binary classification data and returns the F1 score metric\n",
    "    \"\"\"\n",
    "    \n",
    "    recall = classification_sensitivity(actual_class,predicted_class)    \n",
    "    precision = classification_precision(actual_class,predicted_class)\n",
    "\n",
    "    f1_score = (2*(recall)*(precision))/(recall+precision)\n",
    "               \n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.606741573034\n"
     ]
    }
   ],
   "source": [
    "f1_score = classification_f1_score(df['class'],df['scored.class'])\n",
    "print(\"F1 score: \",f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got an F1 score of 0.60674"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__10)__ Write a Python function to __plot a ROC curve and also calculate AUC__ for any binary classification data that contains both actual and predicted classifications as well as the associated scored probabilities without utilizing any pre-built Python classification metric calculation or ROC or AUC functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to plot the ROC (Receiver Operating Characteristic), we will calculate the true positive rate (TPR) (or Sensitivity) against the false positive rate (FPR)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we have a helper function that will define the new scored.probability based on the threshold value that it receives as a parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_class(probability,thresh):\n",
    "    \n",
    "    '''\n",
    "    Creates a new column with the new prediction based on the new threshold\n",
    "    '''\n",
    "    new_df = pd.DataFrame(probability, columns=['scored.probability'])\n",
    "    \n",
    "    new_df[new_df[\"scored.probability\"] >= thresh] = 1\n",
    "    new_df[new_df[\"scored.probability\"] < thresh] = 0\n",
    "    \n",
    "    return new_df[\"scored.probability\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define a function that calculates and plot the ROC, with the corresponding AUC value. We defined a starting point of 0, and a specific threshold of 0.5, ending at 1. We choose this threshold to match what sklearn provides in the prebuilt function.  The user might be able to change it to any other lower value (like 0.1), we it will get a greater AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ROC_and_AUC(actual_class, predicted_class, probability):\n",
    "    '''\n",
    "    Function that receives actual and predicted classifications as well as the associated scored probabilities\n",
    "    for any binary classification model and:\n",
    "    - Plots the ROC with the True Positive Rate (TPR) and False Positive Rate (FPR) for every threshold step.\n",
    "    - Calculate the AUC and include it in the ROC plot as a legend\n",
    "    \n",
    "    Returns TPR, FPR both as a list with the ROC coordinates and the AUC value.\n",
    "    '''\n",
    "    \n",
    "    #start threshold at zero\n",
    "    threshold = 0\n",
    "    \n",
    "    #define empty list for TPR and FPR\n",
    "    tpr_list, fpr_list = [],[]\n",
    "    \n",
    "    #iterates until threshold > 1\n",
    "    while threshold <= 1:\n",
    "        threshold = round(threshold,2)\n",
    "       \n",
    "        #call the function to get the new scored.class based on current threshold     \n",
    "        predicted_class = predict_class(probability,threshold)\n",
    "        \n",
    "        #get the set of classes predicted (can be '0', '1' or '0' and '1')\n",
    "        classes = set(predicted_class)\n",
    "        \n",
    "        #check returned classes count\n",
    "        if (len(classes) == 1):\n",
    "            \n",
    "            #has only one class predicted\n",
    "            if 1 in classes:\n",
    "                #all predicted classes were 1, set the fpr and tpr to 1\n",
    "                tpr = 1\n",
    "                fpr = 1\n",
    "                \n",
    "            else: \n",
    "                #all predicted classes were 0, set the fpr and tpr to 0\n",
    "                tpr = 0\n",
    "                fpr = 0\n",
    "                \n",
    "        else: #we have more than one class predicted, get the confusion matrix and the corresponding values\n",
    "            tpr = classification_sensitivity(actual_class, predicted_class)\n",
    "            fpr = get_fp_rate(actual_class, predicted_class)\n",
    "        \n",
    "        #append calculated tpr and fpr values to corresponding list\n",
    "        tpr_list.append(tpr)\n",
    "        fpr_list.append(fpr)\n",
    "        \n",
    "        #increase the threshold in 0.05\n",
    "        threshold += 0.5\n",
    "    \n",
    "    #call function to calculate AUC\n",
    "    auc_value = auc(fpr_list,tpr_list)\n",
    "    \n",
    "    # calculate ROC curve using fpr and tpr lists\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr_list, tpr_list, label=\"AUC = \"+str(round(auc_value,4)))\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    \n",
    "    #adding coordinate legends\n",
    "    for i_x, i_y in zip(fpr_list, tpr_list):\n",
    "        i_x = round(i_x,2)\n",
    "        i_y = round(i_y,2)\n",
    "        plt.text(i_x, i_y, '({}, {})'.format(i_x, i_y))\n",
    "    \n",
    "    \n",
    "    plt.show();\n",
    "    \n",
    "    return tpr_list, fpr_list, auc_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function to get the false positive rate (will be in the x axis in our ROC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_fp_rate(actual_class, predicted_class):\n",
    "    \"\"\"\n",
    "    Receives 2 list/series with the actual and predicted classifications \n",
    "    for any binary classification data and returns the sensitivity metric\n",
    "    \"\"\"\n",
    "    \n",
    "    tp,tn,fp,fn = get_confusion_elements(actual_class, predicted_class)\n",
    "    \n",
    "    \n",
    "    rate = fp/(fp+tn)\n",
    "    #FPR = FP / (FP + TN)\n",
    "    return rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define a function a helper function to get an area of a trapezoid. [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trapezoid_rule(x1,x2,y1,y2):\n",
    "    \"\"\"\n",
    "    Implementing the trapezoid rule = Height/2 * width\n",
    "    y: TPR.\n",
    "    x: FPR.\n",
    "    \"\"\"\n",
    "    return ((y1+y2)/2) * (x2-x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define a function that will calculate the AUC of the area of a small trapezoids and then add all of them up to get the total area. [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def auc(fpr,tpr):\n",
    "    n = len(fpr)\n",
    "\n",
    "    area = 0\n",
    "    for i in range(n):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        subarea = trapezoid_rule(fpr[i], fpr[i-1], tpr[i], tpr[i-1])\n",
    "        area += subarea\n",
    "    return area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test our ROC_and_AUC function providing the class, scored.class and scored.probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZwAAAEWCAYAAABSaiGHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEEoRHU4IIYRS/A9LSBJ484whIgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23208d9acf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tpr_list, fpr_list, auc = ROC_and_AUC(df['class'], df['scored.class'], df['scored.probability'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC value is : 0.716680814941\n"
     ]
    }
   ],
   "source": [
    "print('AUC value is :', auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get the AUC we calculated small trapezoidal areas (with the helper function) and the sum them all together to get the full area. <br>\n",
    "We see the 45° red doted line which shows a random model but we have better performance as our AUC is greater than 0.5. In addition we added coordinates as a reference for the reader."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__11)__ Apply the Python functions you’ve created to the relevant columns of the provided data set to produce\n",
    "the classification metrics specified in steps 5 through 9 of this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test each of the functions we created from task 5 to task 9 and print the corresponding results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:     0.806629834254\n",
      "Precision:    0.84375\n",
      "Sensitivity:  0.473684210526\n",
      "Specificity:  0.798657718121\n",
      "F1 score:     0.606741573034\n"
     ]
    }
   ],
   "source": [
    "#task 5: accuracy\n",
    "accuracy = get_classification_accuracy(df['class'],df['scored.class'])\n",
    "print(\"Accuracy:    \",accuracy)\n",
    "\n",
    "#task 6: precision\n",
    "precision = classification_precision(df['class'],df['scored.class'])\n",
    "print(\"Precision:   \",precision)\n",
    "\n",
    "#task 7: sensitivity\n",
    "sensitivity = classification_sensitivity(df['class'],df['scored.class'])\n",
    "print(\"Sensitivity: \",sensitivity)\n",
    "\n",
    "#task 8: specificity\n",
    "specificity = classification_specificity(df['class'],df['scored.class'])\n",
    "print(\"Specificity: \",specificity)\n",
    "\n",
    "#task 9: f1_score\n",
    "f1_score = classification_f1_score(df['class'],df['scored.class'])\n",
    "print(\"F1 score:    \",f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see each of the model metrics one after the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__12)__ Now compare the output of your functions against the output of the pre-built functions available within the __scikit-learn__ library. Specifically, apply the __confusion_matrix(), accuracy_score(), precision_score(), recall_score()__ (remember: recall = sensitivity), __f1_score()__, and the __metrics.classification_report()__ functions to the relevant columns of the provided data set. Discuss how well the results of these pre-built functions compare to those of the functions you’ve created for this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the metrics library from sklearn and use each of the prebuilt functions to get the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[119,   5],\n",
       "       [ 30,  27]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "metrics.confusion_matrix(df['class'],df['scored.class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the confusion matrix that matches the one we got from pd.crosstab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:   0.806629834254\n",
      "Precision:  0.84375\n",
      "Recall:     0.473684210526\n",
      "F1 Score:   0.606741573034\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:  \",metrics.accuracy_score(df['class'],df['scored.class']))\n",
    "print(\"Precision: \",metrics.precision_score(df['class'],df['scored.class']))\n",
    "print(\"Recall:    \",metrics.recall_score(df['class'],df['scored.class']))\n",
    "print(\"F1 Score:  \",metrics.f1_score(df['class'],df['scored.class']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our metric with the functions we created matches the ones with the sklearn prebuilt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.96      0.87       124\n",
      "          1       0.84      0.47      0.61        57\n",
      "\n",
      "avg / total       0.81      0.81      0.79       181\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(df['class'],df['scored.class']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__13)__ Using the __metrics.plot_roc_curve ()__ and __metrics.auc()__ functions from the scikit-learn package to generate a ROC plot and calculate AUC for the provided data set. How do the results compare with the ROC/AUC function you’ve created for this assignment?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code uses the prebuilt roc_curve that receives the class and scored.class as a parameter and plots the ROC with its own logic. We added the coordinates as a reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(df['class'], df['scored.class'])\n",
    "plt.plot(fpr,tpr)\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.title('ROC classifier')\n",
    "plt.xlabel('False positive rate (1-Specificity)')\n",
    "plt.ylabel('True positive rate (Sensitivity)')\n",
    "\n",
    "#adding coordinate legends\n",
    "for i_x, i_y in zip(fpr, tpr):\n",
    "    i_x = round(i_x,2)\n",
    "    i_y = round(i_y,2)\n",
    "    plt.text(i_x, i_y, '({}, {})'.format(i_x, i_y))\n",
    "        \n",
    "        \n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the ROC from sklearn matches our ROC from previous task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We print the 3 points that sklearn returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.        ,  0.47368421,  1.        ]),\n",
       " array([ 0.        ,  0.04032258,  1.        ]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpr, fpr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check the AUC value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71668081494057723"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the AUC value of 0.7166 matches the one we got from our function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "[1]https://en.wikipedia.org/wiki/Trapezoidal_rule#:~:text=In%20mathematics%2C%20and%20more%20specifically,for%20approximating%20the%20definite%20integral.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can see that the model we created, as well as the one created by sklearn, shows a higher AUC than a random model, which means it is better than a random model. \n",
    "- The different functions that we created matches the results provided by the prebuilt functions, but this allowed us to understand how classification metrics are calculated.\n",
    "- The different metric values show the specific weight to each metric, with the higher one as precision: 0.84375, which means which percentage of the values that were predictive as true were actually true."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
